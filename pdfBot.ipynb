{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "\n",
    "openai.api_key = api_key\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pdfs into documents & create a vectore store index from those documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"PDF\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Query engine for QA over our index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The research paper introduces the Transformer model, which is based solely on attention mechanisms, eliminating the need for recurrent or convolutional layers. The authors discuss the Transformer's success in machine translation tasks, achieving state-of-the-art results on tasks like English-to-German and English-to-French translations. Additionally, the paper mentions plans to extend the Transformer model to handle tasks involving modalities beyond text, such as images, audio, and video. The authors also express interest in exploring local, restricted attention mechanisms to efficiently process large inputs and outputs.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "\n",
    "response = query_engine.query(\"What can you tell me about vision transformers in the research paper? What contributions were made?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"in rich dad poor dad, what is the main investment advice?\")\n",
    "# response = query_engine.query(\"What can you tell me about vision transformers in the research paper? What contributions were made? List all of the source docments\")\n",
    "# response = query_engine.query(\"How do I go about implementing facets and then what response 200 codes might I receive? Use the provided documents to answer\")\n",
    "# response = query_engine.query(\"What is the corresponding GET for bundle search with provenance\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main investment advice in \"Rich Dad Poor Dad\" is to focus on acquiring knowledge and understanding rather than just buying things. It emphasizes the importance of learning, being knowledgeable about investments, and managing risks effectively.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title page\n",
      "FHIR API Documentation Guide\n",
      "April 2023\n",
      "T able of Contents\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"Give me the full TOC for the oracle FHIR document\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragllama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
