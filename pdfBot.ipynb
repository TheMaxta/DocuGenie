{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pdfs into documents & create a vectore store index from those documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"PDF\").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Query engine for QA over our index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The research paper discusses the Transformer model, which is based solely on attention mechanisms and does not include recurrent or convolutional layers. The authors highlight that the Transformer model can be trained faster than architectures with recurrent or convolutional layers, achieving state-of-the-art results in translation tasks. The paper also mentions plans to extend the Transformer model to handle tasks involving input and output modalities other than text, such as images, audio, and video. Additionally, the authors express interest in exploring local, restricted attention mechanisms to efficiently process large inputs and outputs.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "\n",
    "response = query_engine.query(\"What can you tell me about vision transformers in the research paper? What contributions were made?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"in rich dad poor dad, what is the main investment advice?\")\n",
    "# response = query_engine.query(\"What can you tell me about vision transformers in the research paper? What contributions were made? List all of the source docments\")\n",
    "# response = query_engine.query(\"How do I go about implementing facets and then what response 200 codes might I receive? Use the provided documents to answer\")\n",
    "# response = query_engine.query(\"What is the corresponding GET for bundle search with provenance\")\n",
    "# response = query_engine.query(\"Give me the full TOC for the oracle FHIR document\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main investment advice in \"Rich Dad Poor Dad\" is to focus on acquiring knowledge and understanding rather than just buying things. It emphasizes the importance of learning, being knowledgeable about investments, and managing risks effectively.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragllama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
